hist(crime_list$uber.dist)
ggplot(subset(crime_list, uber.location==100), aes(x=long, y=lat, colour=factor(uber.location))) +
geom_point() +coord_equal() + guides(colour=FALSE) +
xlim(min(crime_list$long), max(crime_list$long))+
ylim(min(crime_list$lat), max(crime_list$lat)) +
geom_point(data=subset(lat.long, locations==100), aes(x=longitude, y=latitude, colour="black"))
ggplot(crime_list, aes(x=long, y=lat, colour=factor(uber.location))) +
geom_point() +coord_equal() + guides(colour=FALSE)
ggplot(subset(crime_list, uber.location==100), aes(x=long, y=lat, colour=factor(uber.location))) +
geom_point() +coord_equal() + guides(colour=FALSE) +
xlim(min(crime_list$long), max(crime_list$long))+
ylim(min(crime_list$lat), max(crime_list$lat)) +
geom_point(data=subset(lat.long, locations==100), aes(x=longitude, y=latitude, colour="black"))
ggplot(subset(crime_list, uber.location==2), aes(x=long, y=lat, colour=factor(uber.location))) +
geom_point() +coord_equal() + guides(colour=FALSE) +
xlim(min(crime_list$long), max(crime_list$long))+
ylim(min(crime_list$lat), max(crime_list$lat)) +
geom_point(data=subset(lat.long, locations==2), aes(x=longitude, y=latitude, colour="black"))
head(lat.long.geoid)
lat.long.geoid %>%
group_by(longitude, latitude) %>%
summarise(count=n()) %>%
filter(count>1)
lat.long.geoid %>%
group_by(longitude, latitude) %>%
dplyr::summarise(count=n()) %>%
filter(count>1)
c(1,2,3,4,5,6) %>% detect(function(n){
n > 3 & n %% 2 == 1
})
library(purrr)
install.packages("purrr")
library(purrr)
c(1,2,3,4,5,6) %>% detect(function(n){
n > 3 & n %% 2 == 1
})
c(1,2,3,4,5,6) %>% detect(function(n){
n > 6 & n %% 2 == 1
})
# use package to import xls files
library(gdata)
library(MASS) ## use for studentized residual calculations off lm's
library(MPV)
b1 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B1.xls')
head(b1)
lm_3.1 <- lm(y~x2 + x7 + x8, data=b1)
# a. Normal probability plot of the residuals. Any problem with normality assumption?
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot")
## The QQ plot does show a slight problem with the normality assumption in the points towards
## the middle of the graph.
# b. Residuals vs. Predicted Response. Interpret.
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="Studentized Residuals", xlab="# Games Won (Fitted)", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(b1$x2, rstudent(lm_3.1), ylab="Residuals", xlab="X2", main="4.2.C Residuals v. Fitted Values\nX2"); abline(0, 0)
plot(b1$x7, rstudent(lm_3.1), ylab="Residuals", xlab="X7", main="4.2.C Residuals v. Fitted Values\nX7"); abline(0, 0)
plot(b1$x8, rstudent(lm_3.1), ylab="Residuals", xlab="X8", main="4.2.C Residuals v. Fitted Values\nX8"); abline(0, 0)
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot")
qqline(lm_3.1$residuals, main="4.2.A QQ Plot")
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot")
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
plot(lm_3.1$fit, lm_3.1$residuals, ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
## Professor Martinet said in office hours we could use the normal $residuals unless otherwise noted
## The model appears to be adequate and does not indicate any
## serious departures from the assumptions.
# c. Construct plots of residuals vs. each regressor. Is the regressor correctly specified?
plot(b1$x2, lm_3.1$residuals, ylab="Residuals", xlab="X2", main="4.2.C Residuals v. Fitted Values\nX2"); abline(0, 0)
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot")
## With Axis flipped and using normal residuals:
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
## With Axis flipped and using normal residuals:
qqnorm(lm_3.1$residuals, main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqline(lm_3.1$residuals, main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
## The QQ plot does show a slight problem with the normality assumption in the points towards
## the middle of the graph.
# b. Residuals vs. Predicted Response. Interpret.
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, lm_3.1$residuals, ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, studentized(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, rstudentized(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, rstandard(lm_3.1), ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, lm_3.1$residuals, ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(b1$x2, lm_3.1$residuals, ylab="Residuals", xlab="X2", main="4.2.C Residuals v. Fitted Values\nX2"); abline(0, 0)
plot(b1$x7, lm_3.1$residuals, ylab="Residuals", xlab="X7", main="4.2.C Residuals v. Fitted Values\nX7"); abline(0, 0)
plot(b1$x8, lm_3.1$residuals, ylab="Residuals", xlab="X8", main="4.2.C Residuals v. Fitted Values\nX8"); abline(0, 0)
plot(b1$x8, rstudent(lm_3.1), ylab="Residuals", xlab="X8", main="4.2.C Residuals v. Fitted Values\nX8"); abline(0, 0)
plot(b1$x8, lm_3.1$residuals, ylab="Residuals", xlab="X8", main="4.2.C Residuals v. Fitted Values\nX8"); abline(0, 0)
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
avPlots(lm_3.1, main="4.2.D Added Variable Plots")
plot(lm_3.1$fit, rstandard(lm_3.1), ylab="Standardized Residuals", xlab="Fitted", main="4.2.E Studentized Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="R-Student Residuals", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1)-rstandard(lm_3.1), ylab="R-Student - Standardized", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstandard(lm_3.1), ylab="Standardized Residuals", xlab="Fitted", main="4.2.E Studentized Residuals v. Fitted Values"); abline(0, 0)
avPlots(lm_3.1, main="4.2.D Added Variable Plots")
plot(lm_3.1$fit, rstandard(lm_3.1), ylab="Standardized Residuals", xlab="Fitted", main="4.2.E Studentized Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="R-Student Residuals", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1)-rstandard(lm_3.1), ylab="R-Student - Standardized", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
b3 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B3.xls')
head(b3)
lm_3.5 <- lm(y~x1 + x6, data=b3)
summary(lm_3.5)
# a. Construct a qq plot of the residuals. Any problem with normality?
qqnorm(rstudent(lm_3.5), main="4.4.A QQ Plot")
qqline(rstudent(lm_3.5), main="4.4.A QQ Plot")
qqnorm(rstudent(lm_3.5), main="4.4.A QQ Plot")
qqline(rstudent(lm_3.5), main="4.4.A QQ Plot")
## There is a slight problem with the normality assumption.
# b. Construct and interpret residuals v. predicted value
plot(lm_3.5$fit, rstudent(lm_3.5), ylab="Studentized Residuals", xlab="# Games Won (Fitted)", main="4.4.B Residuals v. Fitted Values")
abline(0, 0)
# The residuals vs. fitted values plot shows a slight non-linear pattern.
# c. Construct and interpret partial regression plots.
avPlots(lm_3.5, main="4.4.C Added Variable Plots")
plot(lm_3.5$fit, rstudent(lm_3.5)-rstandard(lm_3.5), ylab="R-Student - Standardized", xlab="Fitted", main="4.4.D R-Student Residuals v. Fitted Values"); abline(0, 0)
b1 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B1.xls')
head(b1)
lm_3.1 <- lm(y~x2 + x7 + x8, data=b1)
# a. Normal probability plot of the residuals. Any problem with normality assumption?
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\nRstudent and No Flip")
## With Axis flipped and using normal residuals:
qqnorm(rstudent(lm_3.1), main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
qqline(rstudent(lm_3.1), main="4.2.A QQ Plot\n$Residuals and Flip", datax = TRUE)
## The QQ plot does show a slight problem with the normality assumption in the points towards
## the middle of the graph.
# b. Residuals vs. Predicted Response. Interpret.
plot(lm_3.1$fit, lm_3.1$residuals, ylab="Studentized Residuals", xlab="Fitted Values", main="4.2.B Residuals v. Fitted Values")
abline(0, 0)
plot(lm_3.1$fit, rstandard(lm_3.1), ylab="Studentized Residuals", xlab="Fitted", main="4.2.E Studentized Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1), ylab="R-Student Residuals", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.1$fit, rstudent(lm_3.1)-rstandard(lm_3.1), ylab="R-Student - Studentized", xlab="Fitted", main="4.2.E R-Student Residuals v. Fitted Values"); abline(0, 0)
## In summary, these two approaches highlight model fits using different residual analysis
## and can be used to highlight influential points or outliers respectively.
## In the plot showing the difference between the two we know one point has ~.2 difference between
## the two methods and could be a possible outlier as identified by the r-student approach.
##########################################
# 4.4
##########################################
# Consider MPG regression from 3.5:
b3 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B3.xls')
head(b3)
lm_3.5 <- lm(y~x1 + x6, data=b3)
summary(lm_3.5)
# a. Construct a qq plot of the residuals. Any problem with normality?
qqnorm(rstudent(lm_3.5), main="4.4.A QQ Plot")
qqline(rstudent(lm_3.5), main="4.4.A QQ Plot")
## There is a slight problem with the normality assumption.
# b. Construct and interpret residuals v. predicted value
plot(lm_3.5$fit, rstudent(lm_3.5), ylab="Studentized Residuals", xlab="# Games Won (Fitted)", main="4.4.B Residuals v. Fitted Values")
abline(0, 0)
# The residuals vs. fitted values plot shows a slight non-linear pattern.
# c. Construct and interpret partial regression plots.
avPlots(lm_3.5, main="4.4.C Added Variable Plots")
## X1 has a linear pattern, but X6 is not as clearly linear. The book states that "a horizontal
## band on the partial regression plot indicates that there is no additional useful information in
## (that variable) for predicting y." Which could potentially indicate x6 isn't helping our regression
## too much.
# d. Compute the studentized residuals and R-student residuals. What info is conveyed by these scaled residuals?
plot(lm_3.5$fit, rstandard(lm_3.5), ylab="Studentized", xlab="Fitted", main="4.4.D R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.5$fit, rstandard(lm_3.5), ylab="Studentized", xlab="Fitted", main="4.4.D Studentized Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.5$fit, rstandard(lm_3.5), ylab="R-Student", xlab="Fitted", main="4.4.D R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.5$fit, rstandard(lm_3.5), ylab="Studentized", xlab="Fitted", main="4.4.D Studentized Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.5$fit, rstudent(lm_3.5), ylab="R-Student", xlab="Fitted", main="4.4.D R-Student Residuals v. Fitted Values"); abline(0, 0)
plot(lm_3.5$fit, rstudent(lm_3.5)-rstandard(lm_3.5), ylab="R-Student - Studentized", xlab="Fitted", main="4.4.D R-Student Minus Studentized Residuals v. Fitted Values"); abline(0, 0)
library(MPV)
lm_2.12.a <- lm(usage~temp, data=p2.12)
summary(lm_2.12.a)
# a. Construct a normal plot of the residuals. Any problem with the assumptions?
qqnorm(rstudent(lm_2.12.a), main="4.8.A QQ Plot")
qqline(rstudent(lm_2.12.a), main="4.8.A QQ Plot")
# The residuals appear to be approximately normal but there could be a single outlier value.
# b. Construct and interpret a plot of the residuals vs. the predicted.
plot(lm_2.12.a$fit,
plot(lm_2.12.a$fit, rstudent(lm_2.12.a), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.8.B Residuals v. Fitted Values")
abline(0, 0)
# There is a bit of a pattern in the residuals (early fitted values are low and later are high)
# However they are relatively close to the 0 line on each side.
# c. If the data were collected chronologically then plot the residuals vs. time order and comment
plot(rstudent(lm_2.12.a), main="R-Student residuals vs. collection order")
plot(lm_2.12.a$fit, rstudent(lm_2.12.a), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.8.B Residuals v. Fitted Values")
abline(0, 0)
# There is a bit of a pattern in the residuals (early fitted values are low and later are high)
# However they are relatively close to the 0 line on each side.
# c. If the data were collected chronologically then plot the residuals vs. time order and comment
plot(rstudent(lm_2.12.a), main="R-Student residuals vs. collection order")
## From class we know autocorrelation is when years/times are correlated to each other.
## If these data were collected chronologically we can see that the variances of close
## times are relatively close (i.e. positive autocorrelation)
## Adding time into the model COULD help.
##########################################
# 4.13
##########################################
b5 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B5.xls')
## Model one
lm_3.8 <- lm(y~x6 + x7, data=b5)
summary(lm_3.8)
qqnorm(rstudent(lm_3.8), main="4.13 QQ Plot for Model with X6 & X7")
qqline(rstudent(lm_3.8), main="4.13 QQ Plot for Model with X6 & X7")
plot(lm_3.8$fit, rstudent(lm_3.8), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.13 QQ Plot for Model with X6 & X7\nResiduals v. Fitted Values")
abline(0, 0)
avPlots(lm_3.8, main="4.13 QQ Plot for Model with X6 & X7")
## Model 2
lm_3.8.e <- lm(y~x6, data=b5)
summary(lm_3.8.e)
qqnorm(rstudent(lm_3.8.e), main="4.13 QQ Plot for Model with X6 Only")
qqline(rstudent(lm_3.8.e), main="4.13 QQ Plot for Model with X6 Only")
plot(lm_3.8.e$fit, rstudent(lm_3.8.e), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.13 QQ Plot for Model with X6 Only\nResiduals v. Fitted Values")
abline(0, 0)
## Using PRESS function from our textbook's official package to get PRESS Stat:
PRESS(lm_3.8)
PRESS(lm_3.8.e)
b16 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW3/data-table-B16.xls')
head(b16)
lm_3.16.LifeExp       <- lm(LifeExp       ~ People.per.TV + People.per.Dr, data=b16)
lm_3.16.LifeExpMale   <- lm(LifeExpMale   ~ People.per.TV + People.per.Dr, data=b16)
lm_3.16.LifeExpFemale <- lm(LifeExpFemale ~ People.per.TV + People.per.Dr, data=b16)
# a. For each model construct a QQ plot of the residuals from the full model.
## Is there a problem with normality?
## LifeExp
qqnorm(rstudent(lm_3.16.LifeExp), main="4.25 QQ Plot for LifeExp")
qqline(rstudent(lm_3.16.LifeExp), main="4.25 QQ Plot for LifeExp")
## LifeExpMale
qqnorm(rstudent(lm_3.16.LifeExpMale), main="4.25 QQ Plot for LifeExpMale")
qqline(rstudent(lm_3.16.LifeExpMale), main="4.25 QQ Plot for LifeExpMale")
## LifeExpFemale
qqnorm(rstudent(lm_3.16.LifeExpFemale), main="4.25 QQ Plot for LifeExpFemale")
qqline(rstudent(lm_3.16.LifeExpFemale), main="4.25 QQ Plot for LifeExpFemale")
qqnorm(lm_3.16.LifeExp$residuals, main="4.25 QQ Plot for LifeExp", datax=TRUE)
qqline(lm_3.16.LifeExp$residuals, main="4.25 QQ Plot for LifeExp", datax=TRUE)
plot(lm_3.16.LifeExp$fit, rstudent(lm_3.16.LifeExp), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.25 LifeExp\nResiduals v. Fitted Values")
abline(0, 0)
## LifeExpMale
plot(lm_3.16.LifeExpMale$fit, rstudent(lm_3.16.LifeExpMale), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.25 LifeExpMale\nResiduals v. Fitted Values")
abline(0, 0)
## LifeExpFemale
plot(lm_3.16.LifeExpFemale$fit, rstudent(lm_3.16.LifeExpFemale), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.25 LifeExpFemale \nResiduals v. Fitted Values")
abline(0, 0)
b20 = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/HW4/data-table-B20.xls')
colnames(b20) <- c("x1", "x2", "x3", "x4", "x5", "y")
head(b20)
## In problem from 4.29 we regressed X5 against Y but that approach wasnt significant.
## Assuming that here we should use all X variables
lm_4.29 <- lm(y~., data=b20)
summary(lm_4.29)
qqnorm(rstudent(lm_4.29), main="4.29 QQ Plot for X5")
qqline(rstudent(lm_4.29), main="4.29 QQ Plot for X5")
## Make Studentized v. Predicted plot:
plot(lm_4.29$fit, rstudent(lm_4.29), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.29 Residuals v. Fitted Values")
abline(0, 0)
## The QQ plot does not show big problems with the assumption of normality or any
## skewing in the tails. The Residuals vs. Fitted plot shows a non-linear pattern in the early
## fitted values and some very scattered residuals in the latter fitted values which indicates
qqnorm(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax=FALSE)
qqline(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax=FALSE)
qqnorm(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax=FALSE)
qqline(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax=FALSE)
qqnorm(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax=FALSE)
qqline(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax=FALSE)
qqnorm(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax = FALSE)
qqline(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax = FALSE)
qqnorm(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax = TRUE)
qqline(lm_4.29$residuals, main="4.29 QQ Plot for X5", datax = TRUE)
qqnorm(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax = TRUE)
qqline(rstudent(lm_4.29), main="4.29 QQ Plot for X5", datax = TRUE)
qqnorm(rstudent(lm_4.29), main="4.29 QQ Plot for X5")#, datax = TRUE)
qqline(rstudent(lm_4.29), main="4.29 QQ Plot for X5")#, datax = TRUE)
## Make Studentized v. Predicted plot:
plot(lm_4.29$fit, rstudent(lm_4.29), ylab="Studentized Residuals", xlab="Fitted Vals", main="4.29 Residuals v. Fitted Values")
abline(0, 0)
head(p5.2)
# a. Plot the scatter. Will a straight line be adequate?
plot(p5.2, main="5.2 Scatter Plot")
# No a straight line does not express the relationship of these points.
# There is a non-linear relationship.
# b. Fit the line model. Compute summary stats and resid plots. What are your conclusions?
lm_5.2 <- lm(vapor~temp, data=p5.2)
summary(lm_5.2)
qqnorm(rstudent(lm_5.2), main="5.2 QQ Plot for Temp")
qqline(rstudent(lm_5.2), main="5.2 QQ Plot for Temp")
qqnorm(rstudent(lm_5.2), main="5.2 QQ Plot for Temp", datax=TRUE)
qqline(rstudent(lm_5.2), main="5.2 QQ Plot for Temp", datax=TRUE)
qqnorm(rstudent(lm_5.2), main="5.2 QQ Plot for Temp")#, datax=TRUE)
qqline(rstudent(lm_5.2), main="5.2 QQ Plot for Temp")#, datax=TRUE)
plot(lm_5.2$fit, rstudent(lm_5.2), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.2 Residuals v. Fitted Values")
abline(0, 0)
p5.2.trans <- p5.2
p5.2.trans$temp.trans <- -1/p5.2.trans$temp
p5.2.trans$log_vapor <- log10(p5.2.trans$vapor)
plot(p5.2.trans$temp.trans, p5.2.trans$log_vapor, main="5.2.C Scatter Plot")
lm_5.2.c <- lm(log_vapor~temp.trans, data=p5.2.trans)
summary(lm_5.2.c)
abline(lm_5.2.c)
# The R2 is ~99% and the variable temp is significant.
qqnorm(rstudent(lm_5.2.c), main="5.2 C Transformed Variables QQ Plot for Temp")
qqline(rstudent(lm_5.2.c), main="5.2 C Transformed Variables QQ Plot for Temp")
## Make Studentized v. Predicted plot:
plot(lm_5.2.c$fit, rstudent(lm_5.2.c), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.2.C Transformed Variables Residuals v. Fitted Values")
defects = read.xls('/Users/bradyfowler/Documents/Fall Semester/Modeling_6021/linear_regression_5e_data_sets/Chapter 5/Problems/data-prob-5-5.XLS')
head(defects)
# a. Fit a straight line regression and perform the fit tests.
lm_5.5 <- lm(defects~weeks, data=defects)
summary(lm_5.5)
#               Estimate Std.     Error   t value   Pr(>|t|)
# (Intercept)       -31.6982     9.7758    -3.243    0.00705 **
# weeks               7.2767     0.8692     8.372   2.35e-06 ***
# Residual standard error: 13.11 on 12 degrees of freedom
# Multiple R-squared:  0.8538,	Adjusted R-squared:  0.8416
# F-statistic: 70.09 on 1 and 12 DF,  p-value: 2.354e-06
## y = -31.6982 + 7.2767x
## The R2 indicates about 85% of the variance in Y is explained.
## weeks is significant at the .05 level.
plot(defects$weeks, defects$defects, main="5.5 Scatter of Bottle Defects", xlab="Weeks", ylab="Defects per 1000")
abline(lm_5.5)
plot(defects$weeks, defects$defects, main="5.5 Scatter of Bottle Defects", xlab="Weeks", ylab="Defects per 1000")
abline(lm_5.5)
## Check out the residuals:
qqnorm(rstudent(lm_5.5), main="5.5 QQ Plot")
qqline(rstudent(lm_5.5), main="5.5 QQ Plot")
plot(lm_5.5$fit, rstudent(lm_5.5), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.5 Residuals v. Fitted Values")
source('~/Documents/Fall Semester/Modeling_6021/HW4/hw4_dbf5sd_2.R', echo=TRUE)
lm_5.5.b <- lm(log10(defects)~weeks, data=defects)
summary(lm_5.5.b)
#               Estimate  Std. Error  t value    Pr(>|t|)
# (Intercept)   0.745346   0.075183     9.914    3.93e-07 ***
# weeks         0.075353   0.006685    11.273    9.68e-08 ***
# Residual standard error: 0.1008 on 12 degrees of freedom
# Multiple R-squared:  0.9137,	Adjusted R-squared:  0.9065
# F-statistic: 127.1 on 1 and 12 DF,  p-value: 9.676e-08
plot(defects$weeks, log10(defects$defects), main="5.5 Scatter of Bottle Defects\nTransformed", xlab="Weeks", ylab="ln(Defects per 1000)")
abline(lm_5.5.b)
lm_5.7 <- lm(y~x1+x2+x3, data=b20)
summary(lm_5.7)
lm_5.7 <- lm(y~x1+x2+x3, data=b20)
summary(lm_5.7)
## Check out the residuals:
qqnorm(rstudent(lm_5.7), main="5.7 QQ Plot")
qqline(rstudent(lm_5.7), main="5.7 QQ Plot")
plot(lm_5.7$fit, rstudent(lm_5.7), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7 Residuals v. Fitted Values")
abline(0, 0)
plot(lm_5.7$fit, lm_5.7$residuals, ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7 Residuals v. Fitted Values")
plot(lm_5.7$fit, rstudent(lm_5.7), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7 Residuals v. Fitted Values")
abline(0, 0)
## The QQ plot shows that the normality assumption is being violated a bit and the residuals vs. fitted values
## shows a non linear pattern of some sort.
## I think that we could try logging the response variable to improve the model fit.
lm_5.7.2 <- lm(log10(y)~x1+x2+x3, data=b20)
summary(lm_5.7.2)
qqnorm(rstudent(lm_5.7.2), main="5.7.2 Transformed Y QQ Plot")
qqline(rstudent(lm_5.7.2), main="5.7.2 Transformed Y QQ Plot")
plot(lm_5.7.2$fit, rstudent(lm_5.7.2), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7.2 Transformed \nResiduals v. Fitted Values")
abline(0, 0)
lm_5.7 <- lm(y~x1+x2+x3, data=b20)
summary(lm_5.7)
lm_5.7 <- lm(y~x1+x2+x3+x4+x5, data=b20)
summary(lm_5.7)
lm_5.7 <- lm(y~x1+x2+x3, data=b20)
summary(lm_5.7)
#               Estimate    Std. Error    t value   Pr(>|t|)
# (Intercept) -2618.4180      456.7497     -5.733   5.18e-05 ***
# x1             21.9729        5.6345      3.900   0.001603 **
# x2              3.8178        0.5888      6.484   1.44e-05 ***
# x3             99.6238       22.2771      4.472   0.000527 ***
# Residual standard error: 10.92 on 14 degrees of freedom
# Multiple R-squared:  0.9195,	Adjusted R-squared:  0.9023
# F-statistic: 53.31 on 3 and 14 DF,  p-value: 6.632e-08
## When we rerun with only X1, X2 and X3 the regression is still significant for all three regressors and
## its R2 is now 91.95% which barely changed at all from the "full" model in 4.9. The F statistic is large and its
## P-value significant at the .05 level so we know this regression is significant.
## Check out the residuals:
qqnorm(rstudent(lm_5.7), main="5.7 QQ Plot")
qqline(rstudent(lm_5.7), main="5.7 QQ Plot")
plot(lm_5.7$fit, rstudent(lm_5.7), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7 Residuals v. Fitted Values")
abline(0, 0)
## The QQ plot shows that the normality assumption is being violated a bit and the residuals vs. fitted values
## shows a non linear pattern of some sort.
## I think that we could try logging the response variable to improve the model fit.
lm_5.7.2 <- lm(log10(y)~x1+x2+x3, data=b20)
summary(lm_5.7.2)
#               Estimate  Std. Error  t value   Pr(>|t|)
# (Intercept) -19.14908    7.95389    -2.408    0.03043 *
# x1           -0.05295    0.09812    -0.540    0.59794
# x2            0.03679    0.01025     3.589    0.00297 **
# x3            0.27519    0.38794     0.709    0.48974
# Residual standard error: 0.1901 on 14 degrees of freedom
# Multiple R-squared:  0.9298,	Adjusted R-squared:  0.9148
# F-statistic: 61.84 on 3 and 14 DF,  p-value: 2.549e-08
# The X2 variable is now the only significant variable in the regression and our R2
# went up ever so slightly over the non-logged model. The regression's F-stat and associated
# p-value indicate the regression is significant at the .05 level.
qqnorm(rstudent(lm_5.7.2), main="5.7.2 Transformed Y QQ Plot")
qqline(rstudent(lm_5.7.2), main="5.7.2 Transformed Y QQ Plot")
plot(lm_5.7.2$fit, rstudent(lm_5.7.2), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.7.2 Transformed \nResiduals v. Fitted Values")
abline(0, 0)
## Overall the regression fit seems to be a bit better when you log the response and the QQ plot
## shows the normality assumption doesn't have as much of a problem and there is less of a pattern in
## the residual v fitted values plot.
## However, it looks to me like one point is poorly fitted and the increased R2 predictability isnt
## SUBSTANTIALLY improved to the point where perhaps logging the response isn't a worthwile transformation
## since it increases the complexity of our analysis without really great outcomes (this would obviously depend
## on the desired application of the model!).
##########################################
# 5.9
##########################################
# Remember that calthrate formation in B8?!
# a. Perform a residual analysis.
head(table.b8)
lm_5.9 <- lm(y~x1+x2, data=table.b8)
summary(lm_5.9)
head(table.b8)
lm_5.9 <- lm(y~x1+x2, data=table.b8)
summary(lm_5.9)
#                Estimate   Std. Error   t value    Pr(>|t|)
# (Intercept)   1.109e+01    1.669e+00     6.642  1.48e-07 ***
# x1            3.501e+02    3.968e+01     8.823  3.38e-10 ***
# x2            1.089e-01    9.983e-03    10.912  1.74e-12 ***
# Residual standard error: 4.782 on 33 degrees of freedom
# Multiple R-squared:  0.8415,	Adjusted R-squared:  0.8319
# F-statistic:  87.6 on 2 and 33 DF,  p-value: 6.316e-14
## As a refresher, Rs is 85%, F stat is large enough and significant so the regression
## is significant and both coefficients are significant at the .05 level
## Residual Analyses:
qqnorm(rstudent(lm_5.9), main="5.9 QQ Plot")
qqline(rstudent(lm_5.9), main="5.9 QQ Plot")
plot(lm_5.9$fit, rstudent(lm_5.9), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.9 Residuals v. Fitted Values"); abline(0, 0)
plot(lm_5.9$fit, rstudent(lm_5.9)-rstandard(lm_5.9), ylab="Studentized Minus R-Standard Residuals", xlab="Fitted Vals", main="5.9 Residuals v. Fitted Values"); abline(0, 0)
# The QQ plots show that there is some violation of the normality assumptions (the tails are deviating).
# The residual vs. fitted values show that the residuals open up a bit with higher fitted values.
# We can also identify there is a likely outlier in the mix here (using r student minus rstandard residuals)
# b. Identify the best transformation and apply/repeat resid analysis.
# Try sqrt now
lm_5.9.b2 <- lm(sqrt(y)~x1+x2, data=table.b8)
summary(lm_5.9.b2)
qqnorm(rstudent(lm_5.9.b2), main="5.9 Transformed Y QQ Plot")
qqline(rstudent(lm_5.9.b2), main="5.9 Transformed Y QQ Plot")
plot(lm_5.9.b2$fit, rstudent(lm_5.9.b2), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.9 Transformed Y Residuals v. Fitted Values"); abline(0, 0)
plot(lm_5.9.b2$fit, rstudent(lm_5.9.b2)-rstandard(lm_5.9.b2), ylab="Studentized Minus R-Standard Residuals", xlab="Fitted Vals", main="5.9 Transformed Y\nResiduals v. Fitted Values"); abline(0, 0)
head(table.b9)
lm_5.10 <- lm(y~x1+x2+x3+x4, data=table.b9)
summary(lm_5.10)
#                Estimate   Std. Error   t value    Pr(>|t|)
# (Intercept)     5.89453      4.32508     1.363     0.17828
# x1             -0.47790      0.34002    -1.406     0.16530
# x2              0.18271      0.01718    10.633    3.78e-15 ***
# x3             35.40284     11.09960     3.190     0.00232 **
# x4              5.84391      2.90978     2.008     0.04935 *
# Residual standard error: 5.014 on 57 degrees of freedom
# Multiple R-squared:  0.6914,	Adjusted R-squared:  0.6697
# F-statistic: 31.92 on 4 and 57 DF,  p-value: 5.818e-14
## R squared is ~70% and F stat and its associated p value show that the
## regression is significant at the .05 level.
## X1 is not significant but x2, x3 and x4 are all significant at the .05 level.'
## Residual Analyses:
qqnorm(rstudent(lm_5.10), main="5.10 QQ Plot")
qqline(rstudent(lm_5.10), main="5.10 QQ Plot")
qqnorm(rstudent(lm_5.10), main="5.10 QQ Plot")
qqline(rstudent(lm_5.10), main="5.10 QQ Plot")
# The QQ plot shows that we dont have a really big problem with normality.
plot(lm_5.10$fit, rstudent(lm_5.10), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.10 Residuals v. Fitted Values"); abline(0, 0)
# The residual vs. fitted values show that the residuals are sloped down a bit as fitted values increase (they drift down a bit)
# b. Identify the best transformation and apply/repeat resid analysis.
## To correct these problems identified in the residual analysis and perhaps improve overall
## model fit, we are going to log transform the response variable:
lm_5.10.b <- lm(log10(y)~x1+x2+x3+x4, data=table.b9)
summary(lm_5.10.b)
## try the sqrt transformation!):
lm_5.10.b <- lm(log10(y)~x1+x2+x3+x4, data=table.b9)
summary(lm_5.10.b)
#                Estimate   Std. Error   t value    Pr(>|t|)
# (Intercept)   0.9678203    0.0883107    10.959    1.18e-15 ***
# x1           -0.0070247    0.0069426    -1.012    0.315897
# x2            0.0028534    0.0003509     8.133    4.14e-11 ***
# x3            0.8035242    0.2266350     3.545    0.000791 ***
# x4            0.1106486    0.0594127     1.862    0.067708 .
# Residual standard error: 0.1024 on 57 degrees of freedom
# Multiple R-squared:  0.5894,	Adjusted R-squared:  0.5606
# F-statistic: 20.45 on 4 and 57 DF,  p-value: 1.712e-10
## Residual Analyses:
qqnorm(rstudent(lm_5.10.b), main="5.10.B LN Transformed Y QQ Plot")
qqline(rstudent(lm_5.10.b), main="5.10.B LN Transformed Y QQ Plot")
# The QQ plot shows that we helped the normality assumption a little bit.
plot(lm_5.10.b$fit, rstudent(lm_5.10.b), ylab="Studentized Residuals", xlab="Fitted Vals", main="5.10.B LN Transformed Residuals v. Fitted Values"); abline(0, 0)
# The residuals don't drift quite as much in this transformed version.
# Overall the transformation helped a bit - definitely more than a sqrt transformation would have done
# The R2 decreased a bit and our x4 coefficient is no longer significant.
